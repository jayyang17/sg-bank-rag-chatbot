path:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  output_dir: "data/outputs"

retrieval:
  embedding_model: "all-MiniLM-L6-v2"
  chunk_size: 500
  chunk_overlap: 50
  vector_store_path: "chroma_db"

llm:
  provider: "openai"
  model: "gpt-4"
  temperature: 0
  max_tokens: 1024
prompt_template: |
  You are a financial assistant. Use the following context to answer the question.
  
  Context:
  {context}
  
  Question:
  {question}
  
  Answer:

telegram:
  token: "YOUR_TOKEN"

flask:
  port: 5000

aws:
  s3_bucket: "my-rag-data"
